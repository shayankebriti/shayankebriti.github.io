name: Get Citation Data

on: 
  workflow_dispatch:
  page_build: 
  schedule:
   - cron:  '0 8 * * *'

permissions:
  contents: write

concurrency:
  group: google-scholar-crawler
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
    - uses: actions/checkout@v4
    - name: Verify secret
      env:
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
      run: |
        if [ -z "${GOOGLE_SCHOLAR_ID}" ]; then
          echo "GOOGLE_SCHOLAR_ID secret is not set"; exit 1; 
        fi
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        cache: 'pip'
        cache-dependency-path: google_scholar_crawler/requirements.txt
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r google_scholar_crawler/requirements.txt
    - name: Run crawler (with timeout)
      env: 
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
      run: |
        cd google_scholar_crawler
        timeout 12m python -u main.py || echo "Crawler failed or timed out (non-fatal)"
    - name: Publish results branch
      run: |
        if [ ! -d google_scholar_crawler/results ]; then
          echo "No results generated; skipping publish."
          exit 0
        fi
        cd google_scholar_crawler/results
        git init
        git config --local user.name "${GITHUB_ACTOR}"
        git config --local user.email "actions@github.com"
        export remote_repo="https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/${GITHUB_REPOSITORY}.git"
        git add *.json
        if [[ -n "$(git status --porcelain)" ]]; then
          git commit -m "Updated Citation Data"
          git push "${remote_repo}" HEAD:google-scholar-stats --force
        else
          echo "No changes to commit"
        fi